{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d60823ef",
   "metadata": {},
   "source": [
    "# Overview\n",
    "Subreddits are interesting but it's also cool to learn more about the people in them.  \n",
    "- What do they like to do, \n",
    "- Where do they go on the web\n",
    "- What subreddit's do they interact with  \n",
    "In any group people are there for different reasons. Some are just learning, some are looking to hangout with similar people, and some are looking a chance to teach people. Plenty of other reasons too. These are more specific to /r/learnpython.\n",
    "  \n",
    "If we can group users together we can better understand where the learnpython beginners hang out and how that differs from some of the more experienced people.  \n",
    "  \n",
    "It could help you find more resources to learn about python, other cool subreddits, and give you a glimpse into the hobbies of other programmers.  \n",
    "  \n",
    "\n",
    "  \n",
    "In this notebook, I'll go over some basic analysis on user accounts and give you some ideas for deeper work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fdca9f",
   "metadata": {},
   "source": [
    "## Ethical Considerations\n",
    "So now that I want to show you how to analyze reddit accounts what is fair game? Which account(s) should I use examples for here?  \n",
    "  \n",
    "I did a search for post about privacy and found 2 redditors that indicated not caring about privacy on the internet and that they've accepted that using social media gives up their privacy. So to me these are fair game, if you are one of those 2 users and want to be removed from this example please feel free to message me.  \n",
    "  \n",
    "More on ethics.. Ethics are a funny concept. I think it's up to you to decide what is ethical. In my view ethics always favor the dominant parties in a group in control of the thought leadership. So I'm not the biggest fan of not doing things because someone says they are considered by some to be unethical. In this exercise I did attempt to follow status quo ethics but the choice is yours in your own research.  \n",
    "  \n",
    "I extend these my views on ethics to other things as well. If the API for something like Reddit doesn't work, there is no harm in accessing it by other means and extracting the information you want. Sites like reddit or Facebook use the internet but try as they might they don't control it. One of the favorite techniques used by these sites is obfuscated crap like that mentioned in this [article](https://css-tricks.com/how-facebook-avoids-ad-blockers/).   \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3133df5a",
   "metadata": {},
   "source": [
    "# Lets Begin!\n",
    "Just like with traversing \"CommentTrees\" in posts we'll need to have code to traverse all of a user's comments and posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ddac9a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BojanglesDeloria'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm # Handy for showing progress on longer running jobs\n",
    "from utils import * #Load the utilities we created in other notebooks\n",
    "\n",
    "users=[\"BojanglesDeloria\",\"Namisaur\",\"Net_User\",\"Hotwater3\",\"ExtremelyBeige\",\"Shannnnnnn\",\"battlefieldguy145\"]\n",
    "user=users[0]\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "67bf1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "redditor=reddit.redditor(user)\n",
    "\n",
    "#NOTE These might be slow for redditors with big accounts, rather then make them a list, keeping them in \"generator\" form\n",
    "#  may be a good idea\n",
    "posts=[post for post in redditor.submissions.new()]\n",
    "comments=[comment for comment in redditor.comments.new()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7e5f76c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3e1c1174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modernwarfare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EscapefromTarkov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LivestreamFail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GearsOfWar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>LivestreamFail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>LivestreamFail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>LivestreamFail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>LivestreamFail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subreddit_name\n",
       "0               Delco\n",
       "1       modernwarfare\n",
       "2    EscapefromTarkov\n",
       "3      LivestreamFail\n",
       "4          GearsOfWar\n",
       "..                ...\n",
       "195    LivestreamFail\n",
       "196    LivestreamFail\n",
       "197    LivestreamFail\n",
       "198         AskReddit\n",
       "199    LivestreamFail\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows=[]\n",
    "for c in posts+comments:\n",
    "    row={\n",
    "        \"subreddit_name\": c.subreddit.display_name\n",
    "    }\n",
    "    rows.append(row)\n",
    "user_df=pd.DataFrame(rows)\n",
    "user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee5885",
   "metadata": {},
   "source": [
    "## What do we do with this data?\n",
    "In data science it's common to have data that comes back in terms of a list. If we wanted to compare users using subreddit activity data we would have a mess on our hands. In general you have to take this data and transform it into user attributes.  \n",
    "  \n",
    "Think about this for a little. Knowing a user is active in \"r/cocaine\" is interesting but it might be more informativce to create categories from this data. Things like US illegal drug interest (cocaine, opium, peyote, benzo, etc) and drug interest (trees, cigarettes, as well as anything in the US illegal drug interest category).  \n",
    "  \n",
    "By creating a category we will hit on underlying user behavior, a disregard for conventional laws in the US, modeled by interest in certain categories.   \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "942b870d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gaming': ['games', 'pcgaming', 'modern_warfare'],\n",
       " 'shooters': ['modern_warfare', 'GearsOfWar', 'BlackOps4'],\n",
       " 'outdoor_activity': ['skateboarding', 'running'],\n",
       " 'us_illegal_drugs': ['cocaine', 'benzodiazepines'],\n",
       " 'drugs': ['cocaine', 'benzodiazepines', 'Cigarettes', 'trees']}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding interests function\n",
    "#video games\n",
    "#drugs\n",
    "#us_illegal_drugs\n",
    "interest_mappings={\n",
    "    \"gaming\": [\"games\",\"pcgaming\",\"modern_warfare\"],\n",
    "    \"shooters\": [\"modern_warfare\",\"GearsOfWar\",\"BlackOps4\"],\n",
    "    \"outdoor_activity\": [\"skateboarding\",\"running\"],#ADD more to categories as you see them!\n",
    "    \"us_illegal_drugs\": [\"cocaine\",\"benzodiazepines\"],\n",
    "}\n",
    "interest_mappings['drugs']=interest_mappings['us_illegal_drugs']+[\n",
    "    \"Cigarettes\",\"trees\"\n",
    "]\n",
    "interest_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4a0f0188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interest_in-gaming': 6,\n",
       " 'interest_in-shooters': 3,\n",
       " 'interest_in-outdoor_activity': 1,\n",
       " 'interest_in-us_illegal_drugs': 9,\n",
       " 'interest_in-drugs': 20}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_interests(collection, matches, match_rule=\"ignore_case\"):\n",
    "    if match_rule==\"ignore_case\":\n",
    "        count=len([c for c in collection if any(c.casefold()==m.casefold() for m in matches)])\n",
    "    else:\n",
    "        raise Exception(\"Unsupported match_rule\")\n",
    "    return count\n",
    "row={}\n",
    "for category, matches in interest_mappings.items():\n",
    "    row[\"interest_in-\"+category]=check_interests(user_df['subreddit_name'], matches)\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8228f4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LivestreamFail         35\n",
       "me_irl                 16\n",
       "Music                  12\n",
       "starbucks               9\n",
       "RPClipsGTA              9\n",
       "trees                   9\n",
       "AskReddit               8\n",
       "cocaine                 7\n",
       "pcmasterrace            6\n",
       "horror                  5\n",
       "hiphopheads             5\n",
       "happycrowds             4\n",
       "Tinder                  4\n",
       "Games                   3\n",
       "ledootgeneration        3\n",
       "TownofSalemgame         3\n",
       "oddlysatisfying         3\n",
       "pcgaming                3\n",
       "funny                   3\n",
       "tipofmytongue           2\n",
       "GlobalOffensive         2\n",
       "youtubehaiku            2\n",
       "Nelk                    2\n",
       "Hasan_Piker             2\n",
       "movies                  2\n",
       "explainlikeimfive       2\n",
       "Delco                   2\n",
       "Cigarettes              2\n",
       "benzodiazepines         2\n",
       "buildapc                2\n",
       "Blackops4               2\n",
       "silenthill              2\n",
       "pics                    1\n",
       "videos                  1\n",
       "aww                     1\n",
       "EscapefromTarkov        1\n",
       "GearsOfWar              1\n",
       "livepd                  1\n",
       "myfriendpedro           1\n",
       "AvoidingThePuddle       1\n",
       "forwardsfromgrandma     1\n",
       "mildlyinteresting       1\n",
       "Target                  1\n",
       "nextfuckinglevel        1\n",
       "apexlegends             1\n",
       "Destiny                 1\n",
       "modernwarfare           1\n",
       "StarWars                1\n",
       "CrappyDesign            1\n",
       "cats                    1\n",
       "BlackPeopleTwitter      1\n",
       "TalesFromRetail         1\n",
       "leaves                  1\n",
       "Summit1G                1\n",
       "thelongeryoulook        1\n",
       "Tekken                  1\n",
       "circlejerk              1\n",
       "skateboarding           1\n",
       "todayilearned           1\n",
       "Name: subreddit_name, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df['subreddit_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed799051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4df5cf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit_name</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delco</td>\n",
       "      <td>BojanglesDeloria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modernwarfare</td>\n",
       "      <td>BojanglesDeloria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EscapefromTarkov</td>\n",
       "      <td>BojanglesDeloria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LivestreamFail</td>\n",
       "      <td>BojanglesDeloria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GearsOfWar</td>\n",
       "      <td>BojanglesDeloria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>rant</td>\n",
       "      <td>battlefieldguy145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>rant</td>\n",
       "      <td>battlefieldguy145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>battlefieldguy145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>rant</td>\n",
       "      <td>battlefieldguy145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>rant</td>\n",
       "      <td>battlefieldguy145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1244 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit_name               user\n",
       "0                Delco   BojanglesDeloria\n",
       "1        modernwarfare   BojanglesDeloria\n",
       "2     EscapefromTarkov   BojanglesDeloria\n",
       "3       LivestreamFail   BojanglesDeloria\n",
       "4           GearsOfWar   BojanglesDeloria\n",
       "...                ...                ...\n",
       "1239              rant  battlefieldguy145\n",
       "1240              rant  battlefieldguy145\n",
       "1241  unpopularopinion  battlefieldguy145\n",
       "1242              rant  battlefieldguy145\n",
       "1243              rant  battlefieldguy145\n",
       "\n",
       "[1244 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now compare multiple users who don't care about privacy\n",
    "rows=[]\n",
    "for user in users:\n",
    "    redditor=reddit.redditor(user)\n",
    "\n",
    "    #NOTE These might be slow for redditors with big accounts, rather then make them a list, keeping them in \"generator\" form\n",
    "    #  may be a good idea\n",
    "    posts=[post for post in redditor.submissions.new()]\n",
    "    comments=[comment for comment in redditor.comments.new()]\n",
    "    for c in posts+comments:\n",
    "        row={\n",
    "            \"subreddit_name\": c.subreddit.display_name,\n",
    "            \"user\": user\n",
    "        }\n",
    "        rows.append(row)\n",
    "users_df=pd.DataFrame(rows)\n",
    "users_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4b89ea7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>comment_karma</th>\n",
       "      <th>post_karma</th>\n",
       "      <th>total_karma</th>\n",
       "      <th>cake_day</th>\n",
       "      <th>interest_in-gaming</th>\n",
       "      <th>interest_in-shooters</th>\n",
       "      <th>interest_in-outdoor_activity</th>\n",
       "      <th>interest_in-us_illegal_drugs</th>\n",
       "      <th>interest_in-drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BojanglesDeloria</td>\n",
       "      <td>29680</td>\n",
       "      <td>15</td>\n",
       "      <td>34183</td>\n",
       "      <td>2013-12-31 14:49:45</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtremelyBeige</td>\n",
       "      <td>25578</td>\n",
       "      <td>88</td>\n",
       "      <td>32265</td>\n",
       "      <td>2018-02-20 01:08:33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hotwater3</td>\n",
       "      <td>7815</td>\n",
       "      <td>15</td>\n",
       "      <td>12022</td>\n",
       "      <td>2014-01-02 00:26:01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Namisaur</td>\n",
       "      <td>33080</td>\n",
       "      <td>329</td>\n",
       "      <td>36886</td>\n",
       "      <td>2014-05-27 17:40:41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Net_User</td>\n",
       "      <td>8126</td>\n",
       "      <td>61</td>\n",
       "      <td>11735</td>\n",
       "      <td>2013-04-10 01:53:53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shannnnnnn</td>\n",
       "      <td>7875</td>\n",
       "      <td>549</td>\n",
       "      <td>15168</td>\n",
       "      <td>2017-08-09 11:10:29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>battlefieldguy145</td>\n",
       "      <td>35216</td>\n",
       "      <td>0</td>\n",
       "      <td>44445</td>\n",
       "      <td>2016-05-28 18:26:20</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                user  comment_karma  post_karma  total_karma  \\\n",
       "0   BojanglesDeloria          29680          15        34183   \n",
       "1     ExtremelyBeige          25578          88        32265   \n",
       "2          Hotwater3           7815          15        12022   \n",
       "3           Namisaur          33080         329        36886   \n",
       "4           Net_User           8126          61        11735   \n",
       "5         Shannnnnnn           7875         549        15168   \n",
       "6  battlefieldguy145          35216           0        44445   \n",
       "\n",
       "             cake_day  interest_in-gaming  interest_in-shooters  \\\n",
       "0 2013-12-31 14:49:45                   6                     3   \n",
       "1 2018-02-20 01:08:33                   0                     0   \n",
       "2 2014-01-02 00:26:01                   0                     0   \n",
       "3 2014-05-27 17:40:41                   0                     0   \n",
       "4 2013-04-10 01:53:53                   0                     0   \n",
       "5 2017-08-09 11:10:29                   0                     0   \n",
       "6 2016-05-28 18:26:20                   0                     4   \n",
       "\n",
       "   interest_in-outdoor_activity  interest_in-us_illegal_drugs  \\\n",
       "0                             1                             9   \n",
       "1                             0                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "5                             0                             0   \n",
       "6                             0                             0   \n",
       "\n",
       "   interest_in-drugs  \n",
       "0                 20  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "5                  0  \n",
       "6                  0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows=[]\n",
    "for user, user_df in users_df.groupby(\"user\"):\n",
    "    redditor=reddit.redditor(user)\n",
    "    row={\"user\": user,\n",
    "            \"comment_karma\":redditor.comment_karma,\n",
    "            \"post_karma\": redditor.awardee_karma,\n",
    "            \"total_karma\": redditor.total_karma,\n",
    "             \"cake_day\": pd.to_datetime(redditor.created_utc*1e9),\n",
    "        }\n",
    "    for category, matches in interest_mappings.items():\n",
    "        row[\"interest_in-\"+category]=check_interests(user_df['subreddit_name'], matches)\n",
    "    rows.append(row)\n",
    "user_profile=pd.DataFrame(rows)\n",
    "user_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ea4cd",
   "metadata": {},
   "source": [
    "Nothing in common! We need to come up with a few more categories and consider extending our analysis to include comment and post text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a931a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "interests_mapping={\n",
    "    \"programming\": [\"Terraform\"],\n",
    "    \"anime\": [],\n",
    "    \"asian_culture\": [],#ASIA IS HUGE AND DIVERSE I'M SORRY FOR LUMPING ALL YALL IN ONE BUCKET RIGHT NOW\n",
    "    \"investing\": [],\n",
    "    \"real_estate\": [],\n",
    "    \"apple_products\": [],\n",
    "    \"judgemental\": [\"AmItheAsshole\"],\n",
    "    \"childfree\": [\"Vasectomy\"],\n",
    "    \"conservative\": [\"AdamCarolla\",#could be good for age discrimination (YES THIS CODE IS FOR DISCRIMINATION?!?!?!?!!!!)\n",
    "                     \"\"],\n",
    "    \"bbq\": [\"smoking\"],                  \n",
    "    #add overwatch\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3a83baa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unpopularopinion        35\n",
       "VinylReleases           25\n",
       "saltierthancrait        21\n",
       "marvelstudios           15\n",
       "jobs                    13\n",
       "AskMenOver30             8\n",
       "Parenting                8\n",
       "NoStupidQuestions        6\n",
       "quit_vaping              5\n",
       "Marriage                 4\n",
       "recruitinghell           3\n",
       "stupidpol                3\n",
       "sysadmin                 3\n",
       "AskScienceFiction        3\n",
       "boxoffice                3\n",
       "Blink182                 3\n",
       "applehelp                3\n",
       "Atlanta                  3\n",
       "RealEstate               2\n",
       "mxpx                     2\n",
       "movies                   2\n",
       "personalfinance          2\n",
       "spotify                  2\n",
       "LockdownSkepticism       2\n",
       "povertyfinance           2\n",
       "electronic_cigarette     2\n",
       "hotones                  1\n",
       "juul                     1\n",
       "sleeptrain               1\n",
       "TikTokCringe             1\n",
       "suits                    1\n",
       "toddlers                 1\n",
       "cobrakai                 1\n",
       "legaladvice              1\n",
       "TooAfraidToAsk           1\n",
       "Piracy                   1\n",
       "AskHR                    1\n",
       "AdamCarolla              1\n",
       "landscaping              1\n",
       "smoking                  1\n",
       "youtubetv                1\n",
       "WeTheFifth               1\n",
       "Conservative             1\n",
       "alexa                    1\n",
       "Vasectomy                1\n",
       "apple                    1\n",
       "Name: subreddit_name, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows=99\n",
    "users_df[users_df['user']=='Hotwater3']['subreddit_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f33f879",
   "metadata": {},
   "source": [
    "## Let's also add in sites users support\n",
    "Just like subreddits we can look up the base domains redditors post. We may also be able to use this to find common idealogy. People who like veganism may link to the same resources like a site on animal cruelty or documentary. By analyzing links users post we should be able to find that. And then can connect them to others posting that link even if they don't follow veganism.     \n",
    "  \n",
    "Keep in mind a link isn't always an endorsement. Someone may post something to make fun of it. Adding that [natural language processing/NLP](https://en.wikipedia.org/wiki/Natural_language_processing) understanding to the code is beyond the scope of this tutorial but I'm happy to go into that more in a different tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d7ad7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c9263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b61835d",
   "metadata": {},
   "source": [
    "# Further Work  \n",
    "At the end of the day information is only as good as what you can use it for.   \n",
    "Think before you embark on a big programming task. What will this new data piece enable to you to do and is it worth the effort? That being said, here's some ideas I had:    \n",
    "## Analysis  \n",
    "- Inferring age from interests\n",
    "    - On reddit some people may post their age in common phrases like \"I'm only 23\" or \"Us millenials\" etc. You can create a model that takes their attributes and predicts age using those that stated their age bands as \"training data\".   \n",
    "- Inferring other things\n",
    "    - Once a user has stated something, I'm from Chicago, I like surfing and do it every day, etc. you can do they same modeling exercise. Come up with a likelihood model that someone is also from Chicago.\n",
    "- Should I move to \"XXX\"\n",
    "    - Analyze followers of various city/country subreddits to see how likely you are to have similar interests to redditors in the place you are considering. \n",
    "    - Apply this to any commonalities you might be interested in seeing. Comapre your account to the subreddit's typical users.\n",
    "- Deviation from the  norm\n",
    "    - People on reddit have one major thing in common, they've chosen to user reddit. This is very different from people who have not. It also means they are on the internet, may have relatively stable internet access, among other things.  \n",
    "    - In doing analysis you may want to account for how a user differs from the average reddit user, I'd reckon the average reddit user values formal education and liberal idealogy more than the real world. If you are trying to make sense of people as a whole you may want to temper your expectations a bit in terms of how prevalent certain leaning sites and dogmas may be\n",
    "  \n",
    "Another type of analysis commonly done on users is cluster analysis. What types of users make up this subreddit? There isn't necessarily one typical user, just a most common. Many subgroups and cliques may follow a certain subreddit. Starwars followers would be a good place to see the difference between old and young users.   \n",
    "  \n",
    "## Cool Project Idea\n",
    "Tie in some of the analysis from before and create a reddit plugin (can be browser based) that gives you details of the reddit account you are reading. Show their karma, whether they comment in posts they create, where they are from, their estimated age, etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4accae82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
