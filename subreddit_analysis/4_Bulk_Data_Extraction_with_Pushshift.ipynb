{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4db8bea1",
   "metadata": {},
   "source": [
    "# Using Pushshift to Get Around PRAW request limits\n",
    "When you use the official reddit API with PRAW there's a request limit. For some applications this isn't a big deal, top 1000 recent comments from a user are quite useful. But in some cases you really want to get a ton of data and for that you should use Pushshift. An unofficial copy of reddit that doesn't have these limits and also supports aggregations. Learn more about it here https://github.com/pushshift/api  \n",
    "  \n",
    "In this tutorial I'll show a pretty common use case of using Pushshift to get the \"index\" of post ids and then using PRAW to get data from that. This way you can search for all posts or comments matching something farther back then reddit would let you using sort by new, 1000 most recent posts. \n",
    "  \n",
    "Sidenote for those familiar with Pushshift access in Python: I prefer [PSAW](https://github.com/dmarx/psaw) over [PMAW](https://github.com/mattpodolak/pmaw) because it returns [PRAW](https://praw.readthedocs.io/en/stable/) objects and I am irked how PMAW sets up it's own logger. The speed improvements aren't as significant as I would have thought, PMAW doesn't seem to support aggregations, and working with PRAW objects each time is easier to work with my existing code base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b45901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.4.0 of praw is outdated. Version 7.5.0 was released Sunday November 14, 2021.\n"
     ]
    }
   ],
   "source": [
    "from secret_services import reddit,psaw_pushshift\n",
    "import utils\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e0f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#pmaw example - returns json\n",
    "subreddit_name=\"environment\"\n",
    "word_to_check=\"companies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2b6a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minim\\miniconda3\\envs\\subreddit_analysis\\lib\\site-packages\\psaw\\PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[removed]\n",
      "[deleted]\n",
      "[removed]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[removed]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[removed]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[deleted]\n",
      "[removed]\n",
      "[deleted]\n",
      "[removed]\n",
      "[removed]\n",
      "[deleted]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>score</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hafl3n0</td>\n",
       "      <td>I don't artificially inseminate..... my cows f...</td>\n",
       "      <td>-1</td>\n",
       "      <td>p9wdlq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>haf6krp</td>\n",
       "      <td>Why the fuck cut down the last of the old grow...</td>\n",
       "      <td>16</td>\n",
       "      <td>pbm2jq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>haemz66</td>\n",
       "      <td>I was beginning to believe that the vegan move...</td>\n",
       "      <td>1</td>\n",
       "      <td>pbbq9k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hac5sym</td>\n",
       "      <td>Its just a move by oil companies to keep doing...</td>\n",
       "      <td>8</td>\n",
       "      <td>pbhpam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>habovkv</td>\n",
       "      <td>There's going to be a fight, but it is looking...</td>\n",
       "      <td>2</td>\n",
       "      <td>pbh9tg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>h0bdgsn</td>\n",
       "      <td>Part of it might be due to legal steps that ha...</td>\n",
       "      <td>3</td>\n",
       "      <td>nq7290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>h09i2m4</td>\n",
       "      <td>ü§∑üèª‚Äç‚ôÇÔ∏è \\n\\nVast majority of republicans now agr...</td>\n",
       "      <td>2</td>\n",
       "      <td>nq53zt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>h08pa7z</td>\n",
       "      <td>That is absolutely true, but check this out:  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>nq0j33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>h08h8n7</td>\n",
       "      <td>I mean we are in a capitalist society. It‚Äôs an...</td>\n",
       "      <td>1</td>\n",
       "      <td>np15wg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>h07ao2c</td>\n",
       "      <td>A portion of lumber is milled in Canada, but a...</td>\n",
       "      <td>2</td>\n",
       "      <td>np3j5j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>965 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    comment_id                                       comment_text  score  \\\n",
       "0      hafl3n0  I don't artificially inseminate..... my cows f...     -1   \n",
       "1      haf6krp  Why the fuck cut down the last of the old grow...     16   \n",
       "2      haemz66  I was beginning to believe that the vegan move...      1   \n",
       "3      hac5sym  Its just a move by oil companies to keep doing...      8   \n",
       "4      habovkv  There's going to be a fight, but it is looking...      2   \n",
       "..         ...                                                ...    ...   \n",
       "960    h0bdgsn  Part of it might be due to legal steps that ha...      3   \n",
       "961    h09i2m4  ü§∑üèª‚Äç‚ôÇÔ∏è \\n\\nVast majority of republicans now agr...      2   \n",
       "962    h08pa7z  That is absolutely true, but check this out:  ...      1   \n",
       "963    h08h8n7  I mean we are in a capitalist society. It‚Äôs an...      1   \n",
       "964    h07ao2c  A portion of lumber is milled in Canada, but a...      2   \n",
       "\n",
       "       post  \n",
       "0    p9wdlq  \n",
       "1    pbm2jq  \n",
       "2    pbbq9k  \n",
       "3    pbhpam  \n",
       "4    pbh9tg  \n",
       "..      ...  \n",
       "960  nq7290  \n",
       "961  nq53zt  \n",
       "962  nq0j33  \n",
       "963  np15wg  \n",
       "964  np3j5j  \n",
       "\n",
       "[965 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#psaw example - returns praw objects\n",
    "subreddit_name=\"environment\"\n",
    "word_to_check=\"companies\"\n",
    "comments=psaw_pushshift.search_comments(q=word_to_check, subreddit=subreddit_name, limit=1001, before=1629990795)\n",
    "import pandas as pd\n",
    "\n",
    "post_with_comments=[]\n",
    "for comment in comments:\n",
    "    if word_to_check in comment.body.lower():#case insensitive check\n",
    "        post_with_comments.append(\n",
    "            {\"comment_id\": comment.id, \"comment_text\": comment.body,\"score\": comment.score,\"post\": comment.submission.id\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        #edited or removed comments don't work\n",
    "        print(comment.body)\n",
    "df=pd.DataFrame(post_with_comments)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d783bafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Submission(id='pam1cx')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.submission(df['post'].iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01080f9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:10<00:00,  2.02s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>score</th>\n",
       "      <th>post</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ha15f6s</td>\n",
       "      <td>Yes! Tax plastics, tax meat production, etc. I...</td>\n",
       "      <td>239</td>\n",
       "      <td>p9wdlq</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ha1du14</td>\n",
       "      <td>Plastics is much harder to accurately tax than...</td>\n",
       "      <td>50</td>\n",
       "      <td>p9wdlq</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ha22vw7</td>\n",
       "      <td>Just start banning single use plastics anytime...</td>\n",
       "      <td>17</td>\n",
       "      <td>p9wdlq</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ha2bpqi</td>\n",
       "      <td>We do it with redemption values, those are an ...</td>\n",
       "      <td>12</td>\n",
       "      <td>p9wdlq</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ha2f04u</td>\n",
       "      <td>Oh, definitely, it's just that hose aspulls ca...</td>\n",
       "      <td>11</td>\n",
       "      <td>p9wdlq</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>habovkv</td>\n",
       "      <td>There's going to be a fight, but it is looking...</td>\n",
       "      <td>2</td>\n",
       "      <td>pbh9tg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>habqpnj</td>\n",
       "      <td>Alaska Election Info\\n\\n[Register to Vote](htt...</td>\n",
       "      <td>2</td>\n",
       "      <td>pbh9tg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>habqqui</td>\n",
       "      <td>Would you look at that, all of the words in yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>pbh9tg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>hac33vt</td>\n",
       "      <td>How many bots are there on Reddit anyway?</td>\n",
       "      <td>1</td>\n",
       "      <td>pbh9tg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>hady9ma</td>\n",
       "      <td>I thought anything in a Reconciliation bill ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>pbh9tg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    comment_id                                       comment_text  score  \\\n",
       "0      ha15f6s  Yes! Tax plastics, tax meat production, etc. I...    239   \n",
       "1      ha1du14  Plastics is much harder to accurately tax than...     50   \n",
       "2      ha22vw7  Just start banning single use plastics anytime...     17   \n",
       "3      ha2bpqi  We do it with redemption values, those are an ...     12   \n",
       "4      ha2f04u  Oh, definitely, it's just that hose aspulls ca...     11   \n",
       "..         ...                                                ...    ...   \n",
       "346    habovkv  There's going to be a fight, but it is looking...      2   \n",
       "347    habqpnj  Alaska Election Info\\n\\n[Register to Vote](htt...      2   \n",
       "348    habqqui  Would you look at that, all of the words in yo...      1   \n",
       "349    hac33vt          How many bots are there on Reddit anyway?      1   \n",
       "350    hady9ma  I thought anything in a Reconciliation bill ha...      1   \n",
       "\n",
       "       post  level  \n",
       "0    p9wdlq      1  \n",
       "1    p9wdlq      2  \n",
       "2    p9wdlq      3  \n",
       "3    p9wdlq      3  \n",
       "4    p9wdlq      4  \n",
       "..      ...    ...  \n",
       "346  pbh9tg      1  \n",
       "347  pbh9tg      1  \n",
       "348  pbh9tg      2  \n",
       "349  pbh9tg      3  \n",
       "350  pbh9tg      1  \n",
       "\n",
       "[351 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_discussion_rows=[]\n",
    "#just doing first 5, traverse posts is super slow with 6th post ID and takes a while to do it https://www.reddit.com/r/environment/comments/pam1cx/the_colorado_river_that_supplies_water_to_40/\n",
    "for post_id in tqdm.tqdm(df['post'].iloc[:5]):\n",
    "    comments=utils.traverse_post(reddit.submission(post_id))\n",
    "    for comment,level in comments:\n",
    "        full_discussion_rows.append({\"comment_id\": comment.id, \"comment_text\": comment.body,\"score\": comment.score,\"post\": post_id, \n",
    "     \"level\": level\n",
    "            })\n",
    "full_discussion_df=pd.DataFrame(full_discussion_rows)\n",
    "full_discussion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4935f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_discussion_df.to_csv(\"all_comments_from_found_posts_with_pushshift.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1184c4",
   "metadata": {},
   "source": [
    "# DONE!\n",
    "We've done it, now we've extracted a corpus of posts matching a subreddit and query filter. Use this as you wish. For larger workflows or big posts you may want to add more functionality to utils.traverse_post. It's super slow on that Lake Mead post https://www.reddit.com/r/environment/comments/pam1cx/the_colorado_river_that_supplies_water_to_40/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14aa454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
